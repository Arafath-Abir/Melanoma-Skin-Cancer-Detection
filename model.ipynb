{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries as shown below\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "#from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "\n",
    "import cv2\n",
    "import itertools\n",
    "import pathlib\n",
    "import warnings\n",
    "from PIL import Image\n",
    "from random import randint\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import matthews_corrcoef as MCC\n",
    "from sklearn.metrics import balanced_accuracy_score as BAS\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "#import tensorflow_addons as tfa\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "from tensorflow.keras import Sequential, Input\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, Flatten\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator as IDG\n",
    "from tensorflow.keras.layers import SeparableConv2D, BatchNormalization, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "#model.optimizer.get_config()\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "filepath = r\"/content/drive/MyDrive/Melonoma- Durjoy Voumik sir/dataset/CNN.weights.h5\"\n",
    "\n",
    "### example___filepath = \"path to weight directory/breastCancer_geometric.h5\"\n",
    "\n",
    "\n",
    "checkpoint1 = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,save_weights_only=True,\n",
    "                             save_best_only=True, mode='max')\n",
    "\n",
    "log_csv = CSVLogger(r'/content/drive/MyDrive/Melonoma- Durjoy Voumik sir/dataset/CNN.csv', separator=',', append=False)\n",
    "### example___CSVLogger('path to logs directory/breastCancer_geometric.csv')\n",
    "\n",
    "callbacks_list = [checkpoint1,log_csv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries as shown below\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "# from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "#from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import glob\n",
    "import uuid\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "benign = \"/content/drive/MyDrive/Melonoma- Durjoy Voumik sir/dataset/melanoma_cancer_dataset/train/benign\"\n",
    "aug_benign = \"/content/drive/MyDrive/Melonoma- Durjoy Voumik sir/dataset/melanoma_cancer_dataset/augmented_image/benign\"\n",
    "malignant = \"/content/drive/MyDrive/Melonoma- Durjoy Voumik sir/dataset/melanoma_cancer_dataset/train/malignant\"\n",
    "aug_malignant = \"/content/drive/MyDrive/Melonoma- Durjoy Voumik sir/dataset/melanoma_cancer_dataset/augmented_image/malignant\"\n",
    "\n",
    "def augment_image(src_image_path, dst_image_path, n=True):\n",
    "    images = glob.glob(os.path.join(src_image_path, \"*\"))  # Use os.path.join for cross-platform compatibility\n",
    "\n",
    "    angles = [45, -45, 75, -75]\n",
    "\n",
    "    for img_path in images:\n",
    "        aug_images = augment(img_path, angles, n)\n",
    "\n",
    "        for aug_img in aug_images:\n",
    "            img_id = str(uuid.uuid4())\n",
    "            img_dir_path = os.path.join(dst_image_path, img_id + \".jpg\")  # Use os.path.join for cross-platform compatibility\n",
    "            aug_img.save(img_dir_path)\n",
    "            aug_img.close()\n",
    "\n",
    "# Function to create the destination directory if it doesn't exist\n",
    "def create_directory_if_not_exists(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def add_pad(image, pad=80):\n",
    "    image = np.array(image)[..., :3]\n",
    "    image = Image.fromarray(image)\n",
    "\n",
    "    padding = pad\n",
    "    padding_image = ImageOps.expand(image=image, border=padding, fill=\"white\")\n",
    "    size = (128, 128)\n",
    "    padding_image = padding_image.resize(size)\n",
    "\n",
    "    return padding_image\n",
    "\n",
    "def augment(img_path, angles, n=True):\n",
    "    print(\"Augmenting:\", img_path)\n",
    "    img = Image.open(img_path)\n",
    "    aug_img = [img.copy()]  # Original image without any augmentation\n",
    "\n",
    "    # Flip\n",
    "    aug_img.append(img.transpose(Image.FLIP_LEFT_RIGHT))\n",
    "    aug_img.append(img.transpose(Image.FLIP_TOP_BOTTOM))\n",
    "\n",
    "    for a in angles:\n",
    "        if n:\n",
    "            r = img.rotate(a, expand=1, fillcolor=\"white\")\n",
    "            fh = r.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            fv = r.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "            aug_img.append(fh)\n",
    "            aug_img.append(fv)\n",
    "            aug_img.append(r)\n",
    "\n",
    "    return aug_img\n",
    "\n",
    "# Create destination directories if they don't exist\n",
    "create_directory_if_not_exists(aug_benign)\n",
    "create_directory_if_not_exists(aug_malignant)\n",
    "\n",
    "# augment_image(src_path, dst_path)\n",
    "augment_image(benign, aug_benign)\n",
    "augment_image(malignant, aug_malignant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Combine images for benign class\n",
    "combined_benign = []\n",
    "combined_benign.extend(glob.glob(os.path.join(benign, \"*\")))\n",
    "combined_benign.extend(glob.glob(os.path.join(aug_benign, \"*\")))\n",
    "np.random.shuffle(combined_benign)\n",
    "\n",
    "# Combine images for malignant class\n",
    "combined_malignant = []\n",
    "combined_malignant.extend(glob.glob(os.path.join(malignant, \"*\")))\n",
    "combined_malignant.extend(glob.glob(os.path.join(aug_malignant, \"*\")))\n",
    "np.random.shuffle(combined_malignant)\n",
    "\n",
    "# Destination directories\n",
    "combined_dir_benign = \"/content/drive/MyDrive/Melonoma- Durjoy Voumik sir/dataset/melanoma_cancer_dataset/combined/benign\"\n",
    "combined_dir_malignant = \"/content/drive/MyDrive/Melonoma- Durjoy Voumik sir/dataset/melanoma_cancer_dataset/combined/malignant\"\n",
    "\n",
    "# Create destination directories if they don't exist\n",
    "os.makedirs(combined_dir_benign, exist_ok=True)\n",
    "os.makedirs(combined_dir_malignant, exist_ok=True)\n",
    "\n",
    "# Move combined images to destination directories\n",
    "for i, img_path in enumerate(combined_benign):\n",
    "    shutil.move(img_path, os.path.join(combined_dir_benign, f\"benign_{i}.jpg\"))\n",
    "\n",
    "for i, img_path in enumerate(combined_malignant):\n",
    "    shutil.move(img_path, os.path.join(combined_dir_malignant, f\"malignant_{i}.jpg\"))\n",
    "\n",
    "print(\"Combined and shuffled images saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator = ImageDataGenerator(\n",
    "\n",
    "    rescale=1.0/255,validation_split=0.1\n",
    "    )\n",
    "\n",
    "y_generator=ImageDataGenerator(rescale=1.0/255,validation_split=0.1)\n",
    "\n",
    "\n",
    "\n",
    "training_set = image_generator.flow_from_directory(batch_size=64,directory='/content/drive/MyDrive/Melonoma- Durjoy Voumik sir/dataset/melanoma_cancer_dataset/combined',\n",
    "                                                 #shuffle=True,\n",
    "                                                 target_size=(128,128),\n",
    "                                                 subset=\"training\",\n",
    "                                                 color_mode='rgb',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=42,\n",
    "                                                 class_mode = \"categorical\"\n",
    "                                                 )\n",
    "\n",
    "\n",
    "validation_dataset = y_generator.flow_from_directory(batch_size=64,\n",
    "                                                 directory='/content/drive/MyDrive/Melonoma- Durjoy Voumik sir/dataset/melanoma_cancer_dataset/combined',\n",
    "                                                 shuffle=True,\n",
    "                                                 target_size=(128,128),\n",
    "                                                 subset=\"validation\",\n",
    "\n",
    "                                                color_mode='rgb',\n",
    "                                                 class_mode = \"categorical\"  )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/Melonoma- Durjoy Voumik sir/dataset/melanoma_cancer_dataset/test',\n",
    "                                            target_size=(128,128),\n",
    "                                            batch_size = 64,\n",
    "                                            shuffle=False,\n",
    "                                            color_mode='rgb',\n",
    "                                            class_mode =  \"categorical\"\n",
    "                                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT= 128\n",
    "IMG_WIDTH = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "#model.add(data_augmentation)\n",
    "#model.add(keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(IMG_HEIGHT,IMG_WIDTH, 3)))\n",
    "model.add(keras.layers.Conv2D(filters=16,kernel_size=(3,3),padding='same',activation='relu',kernel_initializer=\"he_normal\"))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters=32,kernel_size=(3,3),padding='same',activation='relu',kernel_initializer=\"he_normal\"))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(keras.layers.Dropout(0.20))\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters=64,kernel_size=(3,3),padding='same',activation='relu',kernel_initializer=\"he_normal\"))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(keras.layers.Dropout(0.25))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128,activation=\"relu\",kernel_initializer=\"he_normal\"))\n",
    "model.add(keras.layers.Dense(64,\"relu\"))\n",
    "model.add(keras.layers.Dense(2,\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import system libs\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import pathlib\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',  # You can choose a different optimizer like 'adam' or 'sgd'\n",
    "              loss='categorical_crossentropy',  # Specify your loss function\n",
    "              metrics=['accuracy'])  # Add any metrics you want to monitor during training\n",
    "\n",
    "r = model.fit(x=training_set, epochs=10, verbose=1, callbacks=callbacks_list,\n",
    "              validation_data=validation_dataset, validation_steps=None, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model.build((None, 128,128,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(r\"/content/drive/MyDrive/Melonoma- Durjoy Voumik sir/dataset/CNN.weights.h5\")\n",
    "Adam = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# Use model.evaluate instead of model.evaluate_generator\n",
    "preds = model.evaluate(training_set)\n",
    "print (\"Loss = \",float(preds[0]))\n",
    "print (\"train Accuracy = \",float(preds[1])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model.load_weights(r\"/content/drive/MyDrive/Melonoma- Durjoy Voumik sir/dataset/CNN.weights.h5\")\n",
    "Adam = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "preds = model.evaluate(test_set)  # Evaluate the model using the test_set\n",
    "print (\"Loss = \",float(preds[0]))\n",
    "print (\"test Accuracy = \",float(preds[1])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### loss and accuracy curve ### updated !!!!!!!!!!\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fin1= pd.read_csv(r'/content/drive/MyDrive/Melonoma- Durjoy Voumik sir/dataset/CNN.csv')\n",
    "\n",
    "\n",
    "### accuracy curve ###\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(fin1['accuracy'], label='Trining accuracy')\n",
    "plt.plot(fin1['val_accuracy'], label='Validation accuracy')\n",
    "plt.legend(loc='lower right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### loss curve ###\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(fin1['loss'], label='Trining loss')\n",
    "plt.plot(fin1['val_loss'], label='Validation loss')\n",
    "\n",
    "plt.title('Loss Curve')\n",
    "\n",
    "plt.savefig(r'/content/drive/MyDrive/Melonoma- Durjoy Voumik sir/dataset/Zrms_loss.png', dpi = 300)\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Make predictions on the validation or test dataset\n",
    "predictions = model.predict(test_set)  # Use the appropriate dataset\n",
    "\n",
    "# Convert the predicted probabilities to class labels\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get the true class labels from the validation or test dataset\n",
    "true_classes = test_set.classes  # Use the appropriate dataset\n",
    "\n",
    "# Generate and print the classification report\n",
    "class_names = test_set.class_indices\n",
    "class_labels = list(class_names.keys())\n",
    "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "print(report)\n",
    "\n",
    "# Generate and plot the confusion matrix\n",
    "confusion = confusion_matrix(true_classes, predicted_classes)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion)\n",
    "\n",
    "# You can also use a heatmap to visualize the confusion matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "!pip install lime\n",
    "import lime\n",
    "import lime.lime_image\n",
    "from skimage.segmentation import mark_boundaries # Import mark_boundaries\n",
    "\n",
    "# Create a LimeImageExplainer object\n",
    "explainer = lime.lime_image.LimeImageExplainer()\n",
    "\n",
    "# Select a random image from the test set for explanation\n",
    "idx = randint(0, len(test_set.filenames) - 1)  # Choose a random image index\n",
    "image_path = test_set.filepaths[idx]\n",
    "image = Image.open(image_path).resize((128, 128))\n",
    "image = np.array(image) / 255.0  # Normalize the image\n",
    "\n",
    "# Get the model's prediction for the chosen image\n",
    "prediction = model.predict(np.expand_dims(image, axis=0))\n",
    "\n",
    "# Explain the prediction using LIME\n",
    "explanation = explainer.explain_instance(image,\n",
    "                                        model.predict,\n",
    "                                        top_labels=2,\n",
    "                                        hide_color=0,\n",
    "                                        num_samples=1000) # Increase num_samples for better results\n",
    "\n",
    "# Display the explanation\n",
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=True)\n",
    "plt.imshow(mark_boundaries(temp, mask)) # Now mark_boundaries is defined and can be used\n",
    "plt.title(f\"Explanation for class: {class_labels[explanation.top_labels[0]]}\")\n",
    "plt.show()\n",
    "\n",
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=10, hide_rest=False)\n",
    "plt.imshow(mark_boundaries(temp, mask)) # Now mark_boundaries is defined and can be used\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "abirenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "-1.-1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
